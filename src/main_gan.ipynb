{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Soni - do**\r\n",
    "## **Generating Music with Machine Learning**\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Author: Sonia Cobo\n",
    "#### Date: July 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Though this project doesn't have a hypothesis per se, it was done to kind off prove how AI has advanced and it is now able to generate music which has been associated with emotions and human capabilities for a long period of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation - dividir canciones, modificarlas para tener mas datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The input to the model will be a series of notes from a MIDI file. MIDI (Musical Instrument Digital Interface) is a technical standard that describes a communications protocol, digital interface, and electrical connectors that connect a wide variety of electronic musical instruments and computers. They don't contain actual audio data and are small in size. They explain what notes are played, when they're played, and how long or loud each note should be.\r\n",
    "\r\n",
    "### To keep the project simple only files with one instrument were chosen, in this case the instrument is piano and the type of songs is classical. \r\n",
    "### These songs have been obtained from the following datasets: http://www.piano-midi.de/ and https://www.mfiles.co.uk/classical-midi.htm\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no descargardas aun: https://github.com/Skuldur/Classical-Piano-Composer/tree/master/midi_songs\n",
    "# https://drive.google.com/file/d/1qnQVK17DNVkU19MgVA4Vg88zRDvwCRXw/view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data manipulation\r\n",
    "import numpy as np\r\n",
    "import pandas as pd \r\n",
    "from random import randint\r\n",
    "\r\n",
    "# manipulate midi files\r\n",
    "import glob\r\n",
    "from music21 import *\r\n",
    "#from music21 import converter, instrument, note, chord, meter, stream, duration, corpus\r\n",
    "import pygame\r\n",
    "\r\n",
    "# visualization\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "# route files\r\n",
    "import os\r\n",
    "import sys\r\n",
    "\r\n",
    "# ml model\r\n",
    "import pickle\r\n",
    "\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow import keras\r\n",
    "\r\n",
    "from keras.utils import np_utils\r\n",
    "from keras.models import Sequential\r\n",
    "from keras.layers import Dense\r\n",
    "from keras.layers import Dropout\r\n",
    "from keras.layers import LSTM\r\n",
    "from keras.layers import Activation\r\n",
    "from keras.layers import BatchNormalization \r\n",
    "from keras.callbacks import ModelCheckpoint\r\n",
    "from keras.layers import Reshape\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf.config.experimental.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7525799484492965909\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\r\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The route of this file is added to the sys path to be able to import/export functions\n",
    "sep = os.sep\n",
    "def route (steps):\n",
    "    \"\"\"\n",
    "    This function appends the route of the file to the sys path\n",
    "    to be able to import files from/to other foders within the EDA project folder.\n",
    "    \"\"\"\n",
    "    route = os.getcwd()\n",
    "    for i in range(steps):\n",
    "        route = os.path.dirname(route)\n",
    "    sys.path.append(route)\n",
    "    return route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\r\n",
    "\r\n",
    "# path to raw data\r\n",
    "path = route(1) + sep + \"data\" + sep + \"raw_data\" + sep\r\n",
    "# path to data in the right key\r\n",
    "path_1 = route(1) + sep + \"data\" + sep + \"converted_data\" + sep\r\n",
    "# path to compiled notes list\r\n",
    "path_2 = route(1) + sep + \"data\" + sep + \"notes\" + sep\r\n",
    "# path to generated models\r\n",
    "path_3 = route(1) + sep + \"models\" + sep\r\n",
    "# path to generated midi files\r\n",
    "path_4 = route(1) + sep + \"reports\" + sep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Midi file exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hablar de frecuencia y la transpuesta de fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All information from the midi file (i.e. notes, pitch, chord, time signature, etc) is contained within the component list\r\n",
    "def info_midi (path):\r\n",
    "    \"\"\"\r\n",
    "    It returns all midi file information given its path\r\n",
    "\r\n",
    "    \"\"\"\r\n",
    "    file = converter.parse(path)\r\n",
    "    components = []\r\n",
    "    for element in file.recurse():  \r\n",
    "        components.append(element)\r\n",
    "    return components\r\n",
    "\r\n",
    "components = info_midi(path + \"alb_esp1.mid\")\r\n",
    "#components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that the midi file has been studied and its structure is known, data will be split into two object types: notes, rests and chords. \r\n",
    "\r\n",
    "### Note objects contain information about the pitch, octave, and offset of the note.\r\n",
    "### Pitch refers to the frequency of the sound, or how high or low it is and is represented with the letters [A, B, C, D, E, F, G].\r\n",
    "### Octave refers to which set of pitches you use on a piano.\r\n",
    "### Offset refers to where the note is located in the piece.\r\n",
    "### Rests are the silences in the piece.\r\n",
    "### Chord objects are a set of notes that are played at the same time.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Songs are transposed into C major and A minor key to ease predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevant information from midi file is encoded and saved into an array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We append the pitch of every note object using its string notation since the most significant parts of the note can be recreated using the string notation of the pitch. And we append every chord by encoding the id of every note in the chord together into a single string, with each note being separated by a dot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each midi file contains notes and chords. These two properties will be the input and output of the LSTM network so \r\n",
    "# they need to be taken out from all midi files. \r\n",
    "\r\n",
    "def get_notes_per_song(path, filename):\r\n",
    "    \"\"\"\r\n",
    "    This function extracts all the notes, rests and chords from one midi file\r\n",
    "    and saves it in a list in the converted_data folder.\r\n",
    "\r\n",
    "    Param: Path of the midi file, filename (str)\r\n",
    "    \"\"\"\r\n",
    "    components = info_midi(path + filename)\r\n",
    "    note_list = []\r\n",
    "    \r\n",
    "    for element in components:\r\n",
    "        # note pitches are extracted\r\n",
    "        if isinstance(element, note.Note):\r\n",
    "            note_list.append(str(element.pitch))\r\n",
    "        # chords are extracted\r\n",
    "        elif isinstance(element, chord.Chord):\r\n",
    "            note_list.append(\".\".join(str(n) for n in element.normalOrder))    \r\n",
    "        # rests are extracted\r\n",
    "        elif isinstance(element, note.Rest):\r\n",
    "            note_list.append(\"NULL\")    #further transformation needs this value as str rather than np.nan\r\n",
    "\r\n",
    "    with open(path_2 + \"notes\", \"wb\") as filepath:\r\n",
    "        pickle.dump(note_list, filepath)\r\n",
    "    \r\n",
    "    return note_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_list = get_notes_per_song(path_1, \"C_alb_esp1.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load notes and chords previously separated\r\n",
    "def load_notes (path, filename):\r\n",
    "    \"\"\"\r\n",
    "    Load the note list containing pitches, rests and chords.\r\n",
    "    \r\n",
    "    Param: Path of the saved note list, and its name as string\r\n",
    "    \"\"\"\r\n",
    "    with open(path + filename, \"rb\") as f:\r\n",
    "        loaded_notes = pickle.load(f)\r\n",
    "        return loaded_notes\r\n",
    "\r\n",
    "note_list = load_notes(path_2, \"notes_chopin\")\r\n",
    "#note_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model will be first trained with a small proportioned of the songs to expedite time. Once the model is tunned properly all songs will be passed to improve its training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that all notes, rests and chords are in a list, these will be transformed from categorical data to integer-based numerical data. It is necessary to create input sequences for the network and their respective outputs. The output for each input sequence will be the first note or chord that comes after the sequence of notes in the input sequence in our list of notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5354"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(note_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, sequence_length, step):\r\n",
    "    \"\"\" \r\n",
    "    Prepare the sequences used by the neural network \r\n",
    "\r\n",
    "    \"\"\"\r\n",
    "    \r\n",
    "    # get all pitchnames\r\n",
    "    pitchnames = sorted(set(notes))\r\n",
    "    print('Total unique notes:', len(pitchnames))\r\n",
    "\r\n",
    "    # create a dictionary to convert pitches (strings) to integers\r\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))  # rests are included  \r\n",
    "\r\n",
    "    network_input = []\r\n",
    "    network_output = []\r\n",
    "\r\n",
    "    #sequence_in = []\r\n",
    "    #sequence_out = []\r\n",
    "\r\n",
    "    # create input sequences and the corresponding outputs\r\n",
    "    for i in range(0, len(notes) - sequence_length, step):    \r\n",
    "        network_input.append(notes[i:i + sequence_length])\r\n",
    "        network_output.append(notes[i + sequence_length])\r\n",
    "        # exchange their values for their integer-code\r\n",
    "\r\n",
    "        # network_input.append([note_to_int[elem] for elem in sequence_in])\r\n",
    "        # network_output.append(note_to_int[sequence_out])\r\n",
    "\r\n",
    "    x = np.zeros((len(network_input), sequence_length, len(pitchnames)))\r\n",
    "    y = np.zeros((len(network_input), len(pitchnames)))\r\n",
    "    for i, sequence in enumerate(network_input):\r\n",
    "        for j, note in enumerate(sequence):\r\n",
    "            x[i, j, note_to_int[note]] = 1\r\n",
    "        y[i, note_to_int[network_output[i]]] = 1\r\n",
    "\r\n",
    "    # n_patterns = len(network_input)\r\n",
    "\r\n",
    "    # reshape the input into a format compatible with LSTM layers\r\n",
    "    # network_input = np.reshape(network_input, (n_patterns, sequence_length, 1)) \r\n",
    "    # normalize input\r\n",
    "    # network_input = network_input / float(len(set(notes)))  \r\n",
    "\r\n",
    "    # network_output = np_utils.to_categorical(network_output) # used to convert array of labeled data to one-hot vector\r\n",
    "\r\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The length of each sequence will be 100 notes/chords for now. This means that to predict the next note in the sequence the network has the previous 100 notes to help make the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique notes: 169\n"
     ]
    }
   ],
   "source": [
    "x, y = prepare_sequences(notes=note_list, sequence_length=100, step=3)  # length y step pueden variar  \r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1752, 100, 169)\n",
      "(1752, 169)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\r\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_notes(model, temperature=1.0):\r\n",
    "    \"\"\" \r\n",
    "    Generate notes from the neural network based on a sequence of notes \r\n",
    "    \"\"\"\r\n",
    "    # pick a random sequence from the input as a starting point for the prediction\r\n",
    "    start = np.random.randint(0, len(note_list)-100-1)\r\n",
    "\r\n",
    "    pitchnames = sorted(set(note_list))\r\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames)) \r\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\r\n",
    "    \r\n",
    "    pattern = note_list[start: (start+100)] \r\n",
    "    prediction_output = []\r\n",
    "    patterns = []\r\n",
    "\r\n",
    "    # generate 500 notes, roughly two minutes of music\r\n",
    "    for note_index in range(5):\r\n",
    "        prediction_input = np.zeros((1, 100, len(pitchnames)))\r\n",
    "        for j, note in enumerate(pattern):\r\n",
    "            prediction_input[0, j, note_to_int[note]] = 1.0\r\n",
    "        preds = model.predict(prediction_input, verbose=0)[0]   #[0]?\r\n",
    "        next_index = sample(preds, temperature=temperature)\r\n",
    "        next_note = int_to_note[next_index]\r\n",
    "\r\n",
    "        pattern = pattern[1:]\r\n",
    "        pattern.append(next_note)\r\n",
    "\r\n",
    "        prediction_output.append(next_note)\r\n",
    "\r\n",
    "        patterns.append(next_index)\r\n",
    "        #patterns = patterns[1:len(patterns)]\r\n",
    "\r\n",
    "    return prediction_output, patterns, next_index, pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\r\n",
    "    # helper function to sample an index from a probability array\r\n",
    "    preds = np.asarray(preds).astype(\"float64\")\r\n",
    "    preds = np.log(preds) / temperature\r\n",
    "    exp_preds = np.exp(preds)\r\n",
    "    preds = exp_preds / np.sum(exp_preds)\r\n",
    "    probas = np.random.multinomial(1, preds, 1)\r\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four different types of layers:\n",
    "\n",
    "LSTM layers is a Recurrent Neural Net layer that takes a sequence as an input and can return either sequences (return_sequences=True) or a matrix.\n",
    "\n",
    "Dropout layers are a regularisation technique that consists of setting a fraction of input units to 0 at each update during the training to prevent overfitting. The fraction is determined by the parameter used with the layer.\n",
    "\n",
    "Dense layers or fully connected layers is a fully connected neural network layer where each input node is connected to each output node.\n",
    "\n",
    "The Activation layer determines what activation function our neural network will use to calculate the output of a node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_model(latent_dim=(x.shape[1], x.shape[2])):\r\n",
    "\r\n",
    "    model = Sequential()\r\n",
    "    model.add(LSTM(512, input_shape=latent_dim, return_sequences=True))\r\n",
    "    model.add(Dense(latent_dim[1]))\r\n",
    "    model.add(Activation(\"softmax\"))\r\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")\r\n",
    "\r\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_68 (LSTM)               (None, 100, 512)          1396736   \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 100, 169)          86697     \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 100, 169)          0         \n",
      "=================================================================\n",
      "Total params: 1,483,433\n",
      "Trainable params: 1,483,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "g = generator_model()\r\n",
    "g.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences_gan(notes, sequence_length, step):\r\n",
    "    \"\"\" \r\n",
    "    Prepare the sequences used by the neural network \r\n",
    "\r\n",
    "    \"\"\"\r\n",
    "    \r\n",
    "    # get all pitchnames\r\n",
    "    pitchnames = sorted(set(notes))\r\n",
    "    print('Total unique notes:', len(pitchnames))\r\n",
    "\r\n",
    "    # create a dictionary to convert pitches (strings) to integers\r\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))  # rests are included  \r\n",
    "\r\n",
    "    network_input = []\r\n",
    "    network_output = []\r\n",
    "\r\n",
    "    #sequence_in = []\r\n",
    "    #sequence_out = []\r\n",
    "\r\n",
    "    # create input sequences and the corresponding outputs\r\n",
    "    for i in range(0, len(notes) - 2*sequence_length, step):    \r\n",
    "        network_input.append(notes[i:i + sequence_length])\r\n",
    "        network_output.append(notes[i + sequence_length : i + 2*sequence_length])\r\n",
    "        # exchange their values for their integer-code\r\n",
    "\r\n",
    "        # network_input.append([note_to_int[elem] for elem in sequence_in])\r\n",
    "        # network_output.append(note_to_int[sequence_out])\r\n",
    "\r\n",
    "    x = np.zeros((len(network_input), sequence_length, len(pitchnames)))\r\n",
    "    y = np.zeros((len(network_input), sequence_length, len(pitchnames)))\r\n",
    "    for i, sequence in enumerate(network_input):\r\n",
    "        for j, note in enumerate(sequence):\r\n",
    "            x[i, j, note_to_int[note]] = 1\r\n",
    "            y[i, j, note_to_int[network_output[i][j]]] = 1\r\n",
    "\r\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3498"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\r\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique notes: 169\n"
     ]
    }
   ],
   "source": [
    "x_gan, y_gan = prepare_sequences_gan(notes=note_list, sequence_length=100, step=3)  # length y step pueden variar  \r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "54/54 [==============================] - 27s 466ms/step - loss: 4.4912\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 25s 457ms/step - loss: 4.1768\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 25s 466ms/step - loss: 3.9955\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 25s 464ms/step - loss: 3.7924\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 25s 462ms/step - loss: 3.4880\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 25s 464ms/step - loss: 3.2052\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 25s 466ms/step - loss: 2.8429\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 25s 469ms/step - loss: 2.5782\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 25s 470ms/step - loss: 2.3153\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 25s 470ms/step - loss: 2.0487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18d489e5788>"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.fit(x_gan, y_gan, epochs=10)  \r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_notes_gan(model, temperature=1.0):\r\n",
    "    \"\"\" \r\n",
    "    Generate notes from the neural network based on a sequence of notes \r\n",
    "    \"\"\"\r\n",
    "    # pick a random sequence from the input as a starting point for the prediction\r\n",
    "    start = np.random.randint(0, len(note_list)-100-1)\r\n",
    "\r\n",
    "    pitchnames = sorted(set(note_list))\r\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames)) \r\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\r\n",
    "    \r\n",
    "    pattern = note_list[start: (start+100)] \r\n",
    "    prediction_output = []\r\n",
    "    patterns = []\r\n",
    "\r\n",
    "    # generate 500 notes, roughly two minutes of music\r\n",
    "\r\n",
    "    prediction_input = np.zeros((1, 100, len(pitchnames)))\r\n",
    "    for j, note in enumerate(pattern):\r\n",
    "        prediction_input[0, j, note_to_int[note]] = 1.0\r\n",
    "    preds = model.predict(prediction_input, verbose=0)[0]   #[0]?\r\n",
    "    \r\n",
    "    for elem in list(preds):\r\n",
    "        next_index = sample(elem, temperature=temperature)\r\n",
    "        next_note = int_to_note[next_index]\r\n",
    "\r\n",
    "        #pattern = pattern[1:]\r\n",
    "        #pattern.append(next_note)\r\n",
    "\r\n",
    "        prediction_output.append(next_note)\r\n",
    "\r\n",
    "        patterns.append(next_index)\r\n",
    "        #patterns = patterns[1:len(patterns)]\r\n",
    "\r\n",
    "    return prediction_output, patterns, next_index, pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NULL', '3', '2.7', 'B-2', 'G3', 'D3', 'E-3', 'B-2', 'E-2', 'F3', '0.3', 'F3', '0.3', 'F3', '0.3', 'NULL', 'F2', 'F3', 'G3', 'NULL', 'B-2', 'B-2', 'NULL', 'NULL', '10.3', '10.3', 'E-2', 'E-2', 'B-1', 'NULL', 'E-3', 'NULL', '8', '11', 'NULL', '3.7.10', 'B-2', 'E-1', 'NULL', 'E-1', 'NULL', 'G#1', 'NULL', 'C#2', '9.11.2.5', 'G#1', 'NULL', 'G#2', 'NULL', '3.6.9', 'NULL', '10.1.5', 'NULL', '3.6.9', '1.5.8', '1.5.8', 'NULL', '7.0', 'G#2', '10.1.5', '1.5.8', 'NULL', 'C#2', '7', 'NULL', 'E-2', '7', 'NULL', 'NULL', 'NULL', '1', 'NULL', 'NULL', 'NULL', '5.8.0', '5.8.0', '1', '3', '8.0.3', 'C3', '2.5', '6.9.0', 'NULL', 'E-3', '2.5', 'C3', 'E-6', 'B2', 'C#4', '1', 'C#4', 'C4', 'C4', 'C4', 'B-3', 'C4', 'C4', 'E4', 'G#4', 'C4']\n"
     ]
    }
   ],
   "source": [
    "prediction_output, patterns, next_index, pattern = generate_notes_gan(g, temperature=1)\r\n",
    "print(prediction_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_midi(prediction_output, patterns, path):\r\n",
    "    \"\"\" convert the output from the prediction to notes and create a midi file from the notes\"\"\"\r\n",
    "    \r\n",
    "    offset = 0\r\n",
    "    output_notes = []\r\n",
    "\r\n",
    "    # create note and chord objects based on the values generated by the model\r\n",
    "    for pattern in prediction_output:\r\n",
    "        # pattern is a chord\r\n",
    "        if ('.' in pattern) or pattern.isdigit():\r\n",
    "            notes_in_chord = pattern.split('.')\r\n",
    "            notes = []\r\n",
    "            for current_note in notes_in_chord:\r\n",
    "                new_note = note.Note(int(current_note))\r\n",
    "                new_note.storedInstrument = instrument.Piano()\r\n",
    "                notes.append(new_note)\r\n",
    "            new_chord = chord.Chord(notes)\r\n",
    "            new_chord.offset = offset\r\n",
    "            output_notes.append(new_chord)\r\n",
    "        # pattern is a rest\r\n",
    "        elif (\"NULL\" in pattern):\r\n",
    "            new_rest = note.Rest(pattern)\r\n",
    "            output_notes.append(new_rest)\r\n",
    "        # pattern is a note\r\n",
    "        else:\r\n",
    "            new_note = note.Note(pattern)   \r\n",
    "            new_note.offset = offset\r\n",
    "            new_note.storedInstrument = instrument.Piano()\r\n",
    "            output_notes.append(new_note)\r\n",
    "\r\n",
    "        # increase offset each iteration so that notes do not stack\r\n",
    "        offset += 0.5\r\n",
    "\r\n",
    "    midi_stream = stream.Stream(output_notes)\r\n",
    "\r\n",
    "    midi_stream.write(\"midi\", fp= path + \"test_output_11_gmodel_chopin.mid\")   # first output 01/07/2021\r\n",
    "\r\n",
    "    return midi_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_midi = create_midi(prediction_output, patterns, path_4)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_music(music_file):\r\n",
    "    \"\"\"\r\n",
    "    Play music given a midi file path\r\n",
    "    \"\"\"\r\n",
    "    import music21\r\n",
    "    try:\r\n",
    "        # allow to stop the piece \r\n",
    "        pygame.mixer.init()\r\n",
    "        clock = pygame.time.Clock() \r\n",
    "        pygame.mixer.music.load(music_file)\r\n",
    "        pygame.mixer.music.play()\r\n",
    "        while pygame.mixer.music.get_busy():\r\n",
    "            # check if playback has finished\r\n",
    "            clock.tick(10)\r\n",
    "\r\n",
    "        freq = 44100    # audio CD quality\r\n",
    "        bitsize = -16   # unsigned 16 bit\r\n",
    "        channels = 2    # 1 is mono, 2 is stereo\r\n",
    "        buffer = 1024    # number of samples\r\n",
    "        pygame.mixer.init(freq, bitsize, channels, buffer)\r\n",
    "\r\n",
    "    except KeyboardInterrupt:\r\n",
    "        while True:\r\n",
    "            action = input('Enter Q to Quit, Enter to Skip.').lower()\r\n",
    "            if action == 'q':\r\n",
    "                pygame.mixer.music.fadeout(1000)\r\n",
    "                pygame.mixer.music.stop()\r\n",
    "            else:\r\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plays music when the cell is executed \r\n",
    "\r\n",
    "play_music(path_4 + \"test_output_11_gmodel_chopin.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1752, 100, 169)\n",
      "(1752, 169)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\r\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hasta aqu√≠ va!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(x):\r\n",
    "    \"\"\"\r\n",
    "    Load and prepare training notes\r\n",
    "    \"\"\"\r\n",
    "    # choose random instances\r\n",
    "    start = np.random.randint(0, len(x)-100-1)\r\n",
    "    # retrieve selected images\r\n",
    "    x_real = x[start: (start+100)] \r\n",
    "    # generate 'real' class labels (1)\r\n",
    "    y_real = np.ones((x.shape[2], 1))\r\n",
    "\r\n",
    "    return x_real, y_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_real, y_real = generate_real_samples(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_points(note_list, x_real, x):\r\n",
    "\r\n",
    "    pitchnames = sorted(set(note_list))\r\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\r\n",
    "\r\n",
    "    # create random matrix of numbers \r\n",
    "    noise = np.random.choice(len(pitchnames)-1, (x_real.shape[0], x.shape[1], x.shape[2]))  #-------\r\n",
    "\r\n",
    "    x_latent = []\r\n",
    "    # transform random int to note\r\n",
    "    for elem in noise[0][0]:\r\n",
    "        fake = int_to_note[abs(int(elem))]\r\n",
    "        x_latent.append(fake)  \r\n",
    "\r\n",
    "    #x_latent = np.array(np.random.shuffle(x_latent,(x_real.shape[0], x.shape[1], x.shape[2])))\r\n",
    "\r\n",
    "    x_latent = np.zeros((x.shape[0], x.shape[1], x.shape[2])))\r\n",
    "    for i, sequence in enumerate(network_input):\r\n",
    "        for j, note in enumerate(sequence):\r\n",
    "            x[i, j, int_to_note[note]] = 1\r\n",
    "\r\n",
    "    return x_latent\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "shuffle() takes exactly one argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-749-6055b442a3e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_latent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_latent_points\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnote_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_real\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx_latent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-748-a9cb05629cc3>\u001b[0m in \u001b[0;36mgenerate_latent_points\u001b[1;34m(note_list, x_real, x)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mx_latent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mx_latent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_latent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_real\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx_latent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: shuffle() takes exactly one argument (2 given)"
     ]
    }
   ],
   "source": [
    "x_latent = generate_latent_points(note_list, x_real, x)\r\n",
    "x_latent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_data(note_list, x_real, x, g_model):\r\n",
    "\t# generate points in latent space\r\n",
    "\tx_fake = generate_latent_points(note_list, x_real, x)\r\n",
    "\t# predict outputs\r\n",
    "\tx_fake = g_model.predict(x_fake)\r\n",
    "\t# create 'fake' class labels (0)\r\n",
    "\ty_fake = np.zeros((x.shape[2], 1))\r\n",
    "\treturn x_fake, y_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py:1544 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py:1527 run_step  *\n        outputs = model.predict_step(data)\n    C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py:1500 predict_step  *\n        return self(x, training=False)\n    C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\base_layer.py:989 __call__  *\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\input_spec.py:212 assert_input_compatibility  *\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_78 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-724-a7d8b61837a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_fake\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_fake_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnote_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_real\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx_fake\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-722-d605abd5083d>\u001b[0m in \u001b[0;36mgenerate_fake_data\u001b[1;34m(note_list, x_real, x, g_model)\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mx_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_latent_points\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnote_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_real\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;31m# predict outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mx_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mg_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_fake\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[1;31m# create 'fake' class labels (0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0my_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1700\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1701\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1702\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1703\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    922\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3020\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m-> 3022\u001b[1;33m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[0;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3439\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[0;32m   3440\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[1;32m-> 3441\u001b[1;33m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[0;32m   3442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[0;32m   3361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m     graph_function = self._create_graph_function(\n\u001b[1;32m-> 3363\u001b[1;33m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[0;32m   3364\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3287\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3288\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3289\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py:1544 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py:1527 run_step  *\n        outputs = model.predict_step(data)\n    C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py:1500 predict_step  *\n        return self(x, training=False)\n    C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\base_layer.py:989 __call__  *\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\input_spec.py:212 assert_input_compatibility  *\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_78 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 1)\n"
     ]
    }
   ],
   "source": [
    "x_fake, y_fake = generate_fake_data(note_list, x_real, x, g)\r\n",
    "x_fake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the standalone discriminator model\r\n",
    "def discriminator_model(n_inputs=(x.shape[1], x.shape[2])):\r\n",
    "\tmodel = Sequential()\r\n",
    "\tmodel.add(LSTM(512, input_shape=n_inputs))\r\n",
    "\tmodel.add(Dense(x.shape[2]))\r\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\r\n",
    "\t# compile model\r\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_72\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_66 (LSTM)               (None, 512)               1396736   \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 169)               86697     \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 1)                 170       \n",
      "=================================================================\n",
      "Total params: 1,483,603\n",
      "Trainable params: 1,483,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "d = discriminator_model()\r\n",
    "d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_model(g_model, d_model):\r\n",
    "\t# make weights in the discriminator not trainable\r\n",
    "\td_model.trainable = False\r\n",
    "\t# connect them\r\n",
    "\tmodel = Sequential()\r\n",
    "\t# add generator\r\n",
    "\tmodel.add(g_model)\r\n",
    "\tmodel.add(BatchNormalization())\r\n",
    "\t# add the discriminator\r\n",
    "\tmodel.add(d_model)\r\n",
    "\t# compile model\r\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=\"adam\")\r\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_78 (Sequential)   (None, 100, 169)          1483433   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 100, 169)          676       \n",
      "_________________________________________________________________\n",
      "sequential_72 (Sequential)   (None, 1)                 1483603   \n",
      "=================================================================\n",
      "Total params: 2,967,712\n",
      "Trainable params: 1,483,771\n",
      "Non-trainable params: 1,483,941\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan_model = gan_model(g, d)\r\n",
    "gan_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, the discriminator model is updated for a half batch of real samples, then a half batch of fake samples, \r\n",
    "# together forming one batch of weight updates. The generator is then updated via the combined GAN model. \r\n",
    "# Importantly, the class label is set to 1 or real for the fake samples. This has the effect of updating the generator toward \r\n",
    "# getting better at generating real samples on the next batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the generator and discriminator\r\n",
    "dataset = generate_real_samples(x)\r\n",
    "\r\n",
    "def train(g_model, d_model, gan_model, x_real, dataset, latent_dim, n_epochs=10, n_batch=128):\r\n",
    "\tbat_per_epo = int(x_real / n_batch)\r\n",
    "\thalf_batch = int(n_batch / 2)\r\n",
    "\t# manually enumerate epochs\r\n",
    "\tfor i in range(n_epochs):\r\n",
    "\t\t# enumerate batches over the training set\r\n",
    "\t\tfor j in range(bat_per_epo):\r\n",
    "\t\t\t# get randomly selected 'real' samples\r\n",
    "\t\t\tx_real, y_real = generate_real_samples(dataset, half_batch)\r\n",
    "\t\t\t# update discriminator model weights\r\n",
    "\t\t\td_loss1, _ = d_model.train_on_batch(x_real, y_real)\r\n",
    "\t\t\t# generate 'fake' examples\r\n",
    "\t\t\tx_fake, y_fake = generate_fake_data(note_list, x_real, x)\r\n",
    "\t\t\t# update discriminator model weights\r\n",
    "\t\t\td_loss2, _ = d_model.train_on_batch(x_fake, y_fake)\r\n",
    "\r\n",
    "\t\t\t# prepare points in latent space as input for the generator\r\n",
    "\t\t\tx_gan = latent(dataset, half_batch)\r\n",
    "\t\t\t# create inverted labels for the fake samples\r\n",
    "\t\t\ty_gan = np.ones((n_batch, 1))\r\n",
    "\t\t\t# update the generator via the discriminator's error\r\n",
    "\t\t\tg_loss = gan_model.train_on_batch(x_gan, y_gan)\r\n",
    "\t\t\t# summarize loss on this batch\r\n",
    "\t\t\tprint('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' %\r\n",
    "\t\t\t\t(i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\r\n",
    "\t\t# evaluate the model performance, sometimes\r\n",
    "\t\t#if (i+1) % 10 == 0:\r\n",
    "\t\t#\tsummarize_performance(i, g_model, d_model, dataset, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(g, d, gan_model, x_real, dataset, latent_dim, n_epochs=100, n_batch=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 14s 375ms/step - loss: 4.0040\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 3s 374ms/step - loss: 3.3438\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 3s 372ms/step - loss: 3.2140\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 3s 369ms/step - loss: 3.0658\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 3s 375ms/step - loss: 3.0402\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 3s 372ms/step - loss: 2.9484\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 3s 370ms/step - loss: 3.0115\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 3s 376ms/step - loss: 2.9082\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 3s 369ms/step - loss: 3.1540\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 3s 368ms/step - loss: 2.8951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x296b86011c8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, epochs=10)#, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\r\n",
    "model.save(path_3 + \"model_5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model \r\n",
    "model_4 = tf.keras.models.load_model(path_3 + \"model_5.h5\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\r\n",
    "    # helper function to sample an index from a probability array\r\n",
    "    preds = np.asarray(preds).astype(\"float64\")\r\n",
    "    preds = np.log(preds) / temperature\r\n",
    "    exp_preds = np.exp(preds)\r\n",
    "    preds = exp_preds / np.sum(exp_preds)\r\n",
    "    probas = np.random.multinomial(1, preds, 1)\r\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_notes(model, x, temperature=1.0):\r\n",
    "    \"\"\" \r\n",
    "    Generate notes from the neural network based on a sequence of notes \r\n",
    "    \"\"\"\r\n",
    "    # pick a random sequence from the input as a starting point for the prediction\r\n",
    "    start = np.random.randint(0, len(note_list)-100-1)\r\n",
    "\r\n",
    "    pitchnames = sorted(set(note_list))\r\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames)) \r\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\r\n",
    "    \r\n",
    "    pattern = note_list[start: (start+100)] # antes tenia x que es menor que note_list por lo que algunos valores start se salian de la lista\r\n",
    "    prediction_output = []\r\n",
    "    patterns = []\r\n",
    "\r\n",
    "    # generate 500 notes, roughly two minutes of music\r\n",
    "    for note_index in range(5):\r\n",
    "        prediction_input = np.zeros((1, 100, len(pitchnames)))\r\n",
    "        for j, note in enumerate(pattern):\r\n",
    "            prediction_input[0, j, note_to_int[note]] = 1.0\r\n",
    "        preds = model.predict(prediction_input, verbose=0)[0]   #[0]?\r\n",
    "        next_index = sample(preds, temperature=temperature)\r\n",
    "        next_note = int_to_note[next_index]\r\n",
    "\r\n",
    "        pattern = pattern[1:]\r\n",
    "        pattern.append(next_note)\r\n",
    "\r\n",
    "        prediction_output.append(next_note)\r\n",
    "\r\n",
    "        patterns.append(next_index)\r\n",
    "        #patterns = patterns[1:len(patterns)]\r\n",
    "\r\n",
    "    return prediction_output, patterns, next_index, pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G#3', 'A3', 'F3', 'G3', 'D4']\n"
     ]
    }
   ],
   "source": [
    "prediction_output, patterns, next_index, pattern = generate_notes(model, x, temperature=1)\r\n",
    "print(prediction_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_midi(prediction_output, patterns, path):\r\n",
    "    \"\"\" convert the output from the prediction to notes and create a midi file from the notes\"\"\"\r\n",
    "    \r\n",
    "    offset = 0\r\n",
    "    output_notes = []\r\n",
    "\r\n",
    "    # create note and chord objects based on the values generated by the model\r\n",
    "    for pattern in prediction_output:\r\n",
    "        # pattern is a chord\r\n",
    "        if ('.' in pattern) or pattern.isdigit():\r\n",
    "            notes_in_chord = pattern.split('.')\r\n",
    "            notes = []\r\n",
    "            for current_note in notes_in_chord:\r\n",
    "                new_note = note.Note(int(current_note))\r\n",
    "                new_note.storedInstrument = instrument.Piano()\r\n",
    "                notes.append(new_note)\r\n",
    "            new_chord = chord.Chord(notes)\r\n",
    "            new_chord.offset = offset\r\n",
    "            output_notes.append(new_chord)\r\n",
    "        # pattern is a rest\r\n",
    "        elif (\"NULL\" in pattern):\r\n",
    "            new_rest = note.Rest(pattern)\r\n",
    "            output_notes.append(new_rest)\r\n",
    "        # pattern is a note\r\n",
    "        else:\r\n",
    "            new_note = note.Note(pattern)   \r\n",
    "            new_note.offset = offset\r\n",
    "            new_note.storedInstrument = instrument.Piano()\r\n",
    "            output_notes.append(new_note)\r\n",
    "\r\n",
    "        # increase offset each iteration so that notes do not stack\r\n",
    "        offset += 0.5\r\n",
    "\r\n",
    "    midi_stream = stream.Stream(output_notes)\r\n",
    "\r\n",
    "    midi_stream.write(\"midi\", fp= path + \"test_output_9.mid\")   # first output 01/07/2021\r\n",
    "\r\n",
    "    return midi_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_midi = create_midi(prediction_output, patterns, path_4)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_music(music_file):\r\n",
    "    \"\"\"\r\n",
    "    Play music given a midi file path\r\n",
    "    \"\"\"\r\n",
    "    import music21\r\n",
    "    try:\r\n",
    "        # allow to stop the piece \r\n",
    "        pygame.mixer.init()\r\n",
    "        clock = pygame.time.Clock() \r\n",
    "        pygame.mixer.music.load(music_file)\r\n",
    "        pygame.mixer.music.play()\r\n",
    "        while pygame.mixer.music.get_busy():\r\n",
    "            # check if playback has finished\r\n",
    "            clock.tick(10)\r\n",
    "\r\n",
    "        freq = 44100    # audio CD quality\r\n",
    "        bitsize = -16   # unsigned 16 bit\r\n",
    "        channels = 2    # 1 is mono, 2 is stereo\r\n",
    "        buffer = 1024    # number of samples\r\n",
    "        pygame.mixer.init(freq, bitsize, channels, buffer)\r\n",
    "\r\n",
    "    except KeyboardInterrupt:\r\n",
    "        while True:\r\n",
    "            action = input('Enter Q to Quit, Enter to Skip.').lower()\r\n",
    "            if action == 'q':\r\n",
    "                pygame.mixer.music.fadeout(1000)\r\n",
    "                pygame.mixer.music.stop()\r\n",
    "            else:\r\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plays music when the cell is executed \r\n",
    "\r\n",
    "play_music(path_4 + \"test_output_8.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d8a740277f67c33143a8e5c8e55f738530a350d8def4a85d8635b690074994c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}