{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **Soni - do**\r\n",
    "# **Generating Music with Machine Learning**\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Author: Sonia Cobo\n",
    "#### Date: July 2021"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Music is associated with emotions, experiences and creativity, all o them considered human's qualities. \r\n",
    "\r\n",
    "### Though this project doesn't have a hypothesis per se it was done to prove that technology has advanced so much that a machine, that cannot experience these feelings, can generate music.\r\n",
    "\r\n",
    "### ...."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# data augmentation - dividir canciones, modificarlas para tener mas datos"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Music files have been imported to Python in MIDI format. MIDI (Musical Instrument Digital Interface) is a technical standard that describes a communications protocol, digital interface, and electrical connectors that connect a wide variety of electronic musical instruments and computers. They don't contain actual audio data and are small in size. They explain what notes are played, when they're played, and how long or loud each note should be.\r\n",
    "\r\n",
    "### To simplify the project only MIDI files consisting of a single instrument were chosen. In this case, the chosen instrument is piano and the type of songs is classical. \r\n",
    "\r\n",
    "### These songs have been obtained from the following datasets: http://www.piano-midi.de/ and https://www.mfiles.co.uk/classical-midi.htm\r\n",
    "### As guidance for the project the following example was considered: 'How to Generate Music using a LSTM Neural Network in Keras' by Sigurður Skúli.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# no descargardas aun: https://github.com/Skuldur/Classical-Piano-Composer/tree/master/midi_songs\n",
    "# https://drive.google.com/file/d/1qnQVK17DNVkU19MgVA4Vg88zRDvwCRXw/view"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import all libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# data manipulation\r\n",
    "import numpy as np\r\n",
    "import pandas as pd \r\n",
    "from sqlalchemy import create_engine\r\n",
    "\r\n",
    "# manipulate midi files\r\n",
    "import glob\r\n",
    "from music21 import *\r\n",
    "#from music21 import converter, instrument, note, chord, meter, stream, duration, corpus\r\n",
    "import pygame\r\n",
    "\r\n",
    "# visualization\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "# route files\r\n",
    "import os\r\n",
    "import sys\r\n",
    "\r\n",
    "# ml model\r\n",
    "import pickle\r\n",
    "\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow import keras\r\n",
    "\r\n",
    "from keras.utils import np_utils\r\n",
    "from keras.models import Sequential\r\n",
    "from keras.layers import Dense\r\n",
    "from keras.layers import Dropout\r\n",
    "from keras.layers import LSTM\r\n",
    "from keras.layers import Activation\r\n",
    "from keras.layers import BatchNormalization as BatchNorm\r\n",
    "from keras.callbacks import ModelCheckpoint\r\n",
    "from keras.layers import Bidirectional\r\n",
    "from keras.layers import Dropout\r\n",
    "from keras.layers import Flatten\r\n",
    "\r\n",
    "# my libraries\r\n",
    "import utils.mining_data_tb as md\r\n",
    "from utils.folders_tb import read_json\r\n",
    "#import utils.visualization_tb as vis\r\n",
    "from utils.sql_tb import MySQL\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.7.4)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Paths"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# The route of this file is added to the sys path to be able to import/export functions\n",
    "sep = os.sep\n",
    "def route (steps):\n",
    "    \"\"\"\n",
    "    This function appends the route of the file to the sys path\n",
    "    to be able to import files from/to other foders within the EDA project folder.\n",
    "    \"\"\"\n",
    "    route = os.getcwd()\n",
    "    for i in range(steps):\n",
    "        route = os.path.dirname(route)\n",
    "    sys.path.append(route)\n",
    "    return route"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# path to raw data\r\n",
    "path = route(1) + sep + \"data\" + sep + \"raw_data\" + sep\r\n",
    "# path to data in the right key\r\n",
    "path_1 = route(1) + sep + \"data\" + sep + \"converted_data\" + sep\r\n",
    "# path to compiled notes list\r\n",
    "path_2 = route(1) + sep + \"data\" + sep + \"notes\" + sep\r\n",
    "# path to generated models\r\n",
    "path_3 = route(1) + sep + \"models\" + sep\r\n",
    "# path to generated midi files\r\n",
    "path_4 = route(1) + sep + \"reports\" + sep"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Midi file exploration"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The Python library 'Music21' has been used to read and manipulate MIDI files. This library has the necessary classes to allow us to read music. \r\n",
    "\r\n",
    "### Hablar de frecuencia y la transpuesta de fourier----------------------------------\r\n",
    "\r\n",
    "### To start working with MIDI files these need to be converted to Score objects, which are a subclass for handling multi-part music. Once this is done it is possible to use the library build-in classes to view the file information."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# All information from the midi file (i.e. notes, pitch, chord, time signature, etc) is contained within the component list\r\n",
    "\r\n",
    "def info_midi (path, filename):\r\n",
    "    \"\"\"\r\n",
    "    It returns all midi file information given its path and filename\r\n",
    "\r\n",
    "    \"\"\"\r\n",
    "    # Convert to Score object\r\n",
    "    file = converter.parse(path + filename)\r\n",
    "    components = []\r\n",
    "    # read file information\r\n",
    "    for element in file.recurse():  \r\n",
    "        components.append(element)\r\n",
    "    return components\r\n",
    "\r\n",
    "components = info_midi(path, \"alb_esp1.mid\")\r\n",
    "#components"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Usig pieces from the same key, in this case C major / A minor assists the model to not go off key."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Ya hecho\r\n",
    "# md.transpose_key(path, path_1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# mejorar graficos mirar video visualizacion borja \r\n",
    "# separar barritas, nombres horizontales"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Knowing all the file components it is possible to select the useful ones for our prediction. The main components to generate new melodies are notes, rests and chords.\r\n",
    "\r\n",
    "### Note objects contain information about the pitch, octave, and offset of the note. Pitch refers to the frequency of the sound, or how high or low it is and is represented with the letters [A, B, C, D, E, F, G] or [Do, Re, Mi, Fa, Sol, La, Si] in Spanish. Octave refers to which set of pitches you use on a piano. Offset refers to where the note is located in the piece.\r\n",
    "\r\n",
    "(añadir visualizacion de lo de arriba para enseñar que es pitch, etc)\r\n",
    "\r\n",
    "### Rests are the silences in the piece.\r\n",
    "### Chord objects are a set of notes that are played at the same time.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#  probar que pasa si le meto cualquier midi, de varios instrumentos, etc\r\n",
    "# data augmentation = min_notes_freq"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## EDA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Relevant information from midi file is encoded and saved into an array."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### We append the pitch of every note object using its string notation since the most significant parts of the note can be recreated using the string notation of the pitch. And we append every chord by encoding the id of every note in the chord together into a single string, with each note being separated by a dot. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Each midi file contains notes and chords. These two properties will be the input and output of the LSTM network so \r\n",
    "# they need to be taken out from all midi files. \r\n",
    "\r\n",
    "def get_notes_per_song(path, filename, save_path, save_name):\r\n",
    "    \"\"\"\r\n",
    "    This function extracts all the notes, rests and chords from one midi file\r\n",
    "    and saves it in a list in the converted_data folder.\r\n",
    "\r\n",
    "    Param: Path of the midi file, filename (str)\r\n",
    "    \"\"\"\r\n",
    "    components = info_midi(path, filename)\r\n",
    "    note_list = []\r\n",
    "    \r\n",
    "    for element in components:\r\n",
    "        # note pitches are extracted\r\n",
    "        if isinstance(element, note.Note):\r\n",
    "            note_list.append(str(element.pitch))\r\n",
    "        # chords are extracted\r\n",
    "        elif isinstance(element, chord.Chord):\r\n",
    "            note_list.append(\".\".join(str(n) for n in element.normalOrder))    \r\n",
    "        # rests are extracted\r\n",
    "        elif isinstance(element, note.Rest):\r\n",
    "            note_list.append(\"NULL\")    #further transformation needs this value as str rather than np.nan\r\n",
    "\r\n",
    "    # save list with all componenets extracted\r\n",
    "    with open(save_path + save_name, \"wb\") as filepath:\r\n",
    "        pickle.dump(note_list, filepath)\r\n",
    "    \r\n",
    "    return note_list"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "one_song = get_notes_per_song(path_1, \"C_alb_esp1.mid\", path_2, \"one_notes\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def get_all_notes(path, save_name, save_path):\r\n",
    "    \"\"\"\r\n",
    "    This function extracts all the notes, rests and chords from all midi files \r\n",
    "    and saves it in a list in the converted_data folder.\r\n",
    "\r\n",
    "    Param: Path of the midi file     \r\n",
    "    \"\"\"\r\n",
    "    all_notes = []\r\n",
    "    list_path = os.listdir(path)\r\n",
    "    for filename in list_path:\r\n",
    "        output = get_notes_per_song(path, filename, save_path, save_name)\r\n",
    "        all_notes += output\r\n",
    "        \r\n",
    "    return all_notes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "all_notes = get_all_notes(path = path_1, save_path = path_2, save_name = \"all_notes\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "print(len(all_notes))\r\n",
    "print(len(set(all_notes)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "696938\n",
      "604\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Load notes and chords previously separated\r\n",
    "def load_notes (path, filename):\r\n",
    "    \"\"\"\r\n",
    "    Load the note list containing pitches, rests and chords.\r\n",
    "    \r\n",
    "    Param: Path of the saved note list, and its name as string\r\n",
    "    \"\"\"\r\n",
    "    with open(path + filename, \"rb\") as f:\r\n",
    "        loaded_notes = pickle.load(f)\r\n",
    "        return loaded_notes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "load_chopin = load_notes(path_2, \"notes_chopin\")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The model will be first trained with a small proportioned of the songs to expedite time. Once the model is tunned properly all songs will be passed to improve its training."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now that all notes, rests and chords are in a list, these will be transformed from categorical data to integer-based numerical data. It is necessary to create input sequences for the network and their respective outputs. The output for each input sequence will be the first note or chord that comes after the sequence of notes in the input sequence in our list of notes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The length of each sequence will be 100 notes/chords for now. This means that to predict the next note in the sequence the network has the previous 100 notes to help make the prediction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# generate dataframe\r\n",
    "\r\n",
    "def create_dataframe(path, save_path, save_name):\r\n",
    "    \"\"\"\r\n",
    "    Create a dataframe and a list with all pieces title and the notes, rests and chrods included in the piece. \r\n",
    "\r\n",
    "    Param: Path of the midi file, filename (str), path where the list will be saved and its name.\r\n",
    "    \"\"\"\r\n",
    "    list_path = os.listdir(path)\r\n",
    "    piece_list = []\r\n",
    "    notes = []\r\n",
    "    for elem in list_path:\r\n",
    "        output = get_notes_per_song(path, elem, save_path, save_name)\r\n",
    "        piece_list.append(elem[:-4])\r\n",
    "        notes.append(output)\r\n",
    "\r\n",
    "    df = pd.DataFrame.from_dict({\"Piece\":piece_list, \"Notes\":notes}, orient=\"index\")\r\n",
    "    df = df.transpose()\r\n",
    "\r\n",
    "    notes = [item for sublist in notes for item in sublist]\r\n",
    "\r\n",
    "    return df, notes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "df_music, note_list = create_dataframe(path= path_1, save_path = path_2, save_name = \"all_notes\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "n = [item for sublist in note_list for item in sublist]\r\n",
    "len(set(n))\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "604"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_music"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                             Piece  \\\n",
       "0                       C_alb_esp1   \n",
       "1                       C_alb_esp2   \n",
       "2                       C_alb_esp3   \n",
       "3                       C_alb_esp4   \n",
       "4                       C_alb_esp5   \n",
       "..                             ...   \n",
       "337                  C_waldstein_1   \n",
       "338                  C_waldstein_2   \n",
       "339                  C_waldstein_3   \n",
       "340  C_waltz-op18-grande-brillante   \n",
       "341               C_Waltz-op64-no2   \n",
       "\n",
       "                                                 Notes  \n",
       "0    [NULL, E5, B5, A5, A5, G5, A5, B5, C6, D6, B5,...  \n",
       "1    [NULL, G3, 0.4.7, NULL, G3, 0.4.7, 7.0, E4, F4...  \n",
       "2    [E5, NULL, G#5, NULL, B5, NULL, A5, A5, F5, NU...  \n",
       "3    [A5, NULL, E5, NULL, F5, NULL, A5, NULL, G#5, ...  \n",
       "4    [NULL, 0.4, 11.2, 2.5, 11.2, 0.4, 9.0, 5.9, 4....  \n",
       "..                                                 ...  \n",
       "337  [NULL, 0.4, NULL, 0.4, NULL, 0.4, NULL, 0.4, N...  \n",
       "338  [NULL, C3, NULL, A3, NULL, A3, A3, NULL, 4.8, ...  \n",
       "339  [NULL, A5, G5, A5, G5, A5, G5, A5, G5, A5, G5,...  \n",
       "340  [D5, D5, NULL, D5, NULL, D5, D5, NULL, D5, NUL...  \n",
       "341  [E4, 11.3, NULL, E2, G4, NULL, 2.4, 8.11.2.4, ...  \n",
       "\n",
       "[342 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Piece</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_alb_esp1</td>\n",
       "      <td>[NULL, E5, B5, A5, A5, G5, A5, B5, C6, D6, B5,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_alb_esp2</td>\n",
       "      <td>[NULL, G3, 0.4.7, NULL, G3, 0.4.7, 7.0, E4, F4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_alb_esp3</td>\n",
       "      <td>[E5, NULL, G#5, NULL, B5, NULL, A5, A5, F5, NU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_alb_esp4</td>\n",
       "      <td>[A5, NULL, E5, NULL, F5, NULL, A5, NULL, G#5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_alb_esp5</td>\n",
       "      <td>[NULL, 0.4, 11.2, 2.5, 11.2, 0.4, 9.0, 5.9, 4....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>C_waldstein_1</td>\n",
       "      <td>[NULL, 0.4, NULL, 0.4, NULL, 0.4, NULL, 0.4, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>C_waldstein_2</td>\n",
       "      <td>[NULL, C3, NULL, A3, NULL, A3, A3, NULL, 4.8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>C_waldstein_3</td>\n",
       "      <td>[NULL, A5, G5, A5, G5, A5, G5, A5, G5, A5, G5,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>C_waltz-op18-grande-brillante</td>\n",
       "      <td>[D5, D5, NULL, D5, NULL, D5, D5, NULL, D5, NUL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>C_Waltz-op64-no2</td>\n",
       "      <td>[E4, 11.3, NULL, E2, G4, NULL, 2.4, 8.11.2.4, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>342 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "source": [
    "# Save cleaned data in the appropriate folder, in this case it is the folder 'data'\r\n",
    "def save_dataframe(dataframe, dataframe_name, steps):\r\n",
    "    \"\"\"\r\n",
    "    Create a cvs file from a dataframe.\r\n",
    "    Param: Dataframe to save, dataframe name as string to save the data with that name\r\n",
    "    \"\"\"\r\n",
    "    dataframe.reset_index(inplace = True)\r\n",
    "    if \"index\" in dataframe.columns:\r\n",
    "        dataframe.drop(columns = \"index\", inplace = True)\r\n",
    "    dataframe.to_csv(route(steps) + os.sep + \"data\" + os.sep + \"output\" + os.sep + dataframe_name + \".csv\", index=False)\r\n",
    "    return \"Your file has been saved\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "source": [
    "df_music = save_dataframe(df_music, \"df_music\", 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "source": [
    "df_music"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Your file has been saved'"
      ]
     },
     "metadata": {},
     "execution_count": 267
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-processing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "source": [
    "def prepare_sequences(notes, min_note_occurence, sequence_length, step):\r\n",
    "    \"\"\" \r\n",
    "    This function creates the input and output sequences used by the neural network.\r\n",
    "    It returns the x and y of the model.\r\n",
    "\r\n",
    "    Param: \r\n",
    "        Note: List containing all notes, rests and chords\r\n",
    "        Sequence_length: Lenght of notes given to the model to help predict the next\r\n",
    "        Step: Step (int) between one input sequence and the next one\r\n",
    "    \"\"\"\r\n",
    "    \r\n",
    "    # get all pitchnames\r\n",
    "    pitchnames = sorted(set(notes))\r\n",
    "    print('Total unique notes:', len(pitchnames))\r\n",
    "\r\n",
    "    # Calculate occurence\r\n",
    "    note_freq = {}\r\n",
    "    for elem in notes:\r\n",
    "        note_freq[elem] = note_freq.get(elem, 0) + 1\r\n",
    "\r\n",
    "    ignored_notes = set()\r\n",
    "    for k, v in note_freq.items():\r\n",
    "        if note_freq[k] < min_note_occurence:\r\n",
    "            ignored_notes.add(k)\r\n",
    "    \r\n",
    "    \r\n",
    "    print('Unique words before ignoring:', len(pitchnames))\r\n",
    "    print('Ignoring words with occurence <', min_note_occurence)\r\n",
    "    pitchnames = sorted(set(pitchnames) - ignored_notes)\r\n",
    "    print('Unique words after ignoring:', len(pitchnames))\r\n",
    "\r\n",
    "    # create a dictionary to convert pitches (strings) to integers\r\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))  # rests are included  \r\n",
    "\r\n",
    "    network_input = []\r\n",
    "    network_output = []\r\n",
    "\r\n",
    "    # create input sequences and the corresponding outputs\r\n",
    "    for i in range(0, len(notes) - sequence_length, step): \r\n",
    "        # remove ignored notes from the note list   \r\n",
    "        if len(set(notes[i: i+ sequence_length + 1]).intersection(ignored_notes)) == 0:\r\n",
    "            network_input.append(notes[i:i + sequence_length])\r\n",
    "            network_output.append(notes[i + sequence_length])\r\n",
    "    # array of zeros\r\n",
    "    x = np.zeros((len(network_input), sequence_length, len(pitchnames)))\r\n",
    "    y = np.zeros((len(network_input), len(pitchnames)))\r\n",
    "    # exchange note values for their integer-code\r\n",
    "    for i, sequence in enumerate(network_input):\r\n",
    "        for j, note in enumerate(sequence):\r\n",
    "            x[i, j, note_to_int[note]] = 1\r\n",
    "        y[i, note_to_int[network_output[i]]] = 1\r\n",
    "\r\n",
    "    return x, y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "source": [
    "x, y = prepare_sequences(notes=load_chopin, min_note_occurence=1, sequence_length=100, step=3)  # length y step pueden variar  \r\n",
    "\r\n",
    "# o coger menos canciones - añadirlo en la memoria\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total unique notes: 109\n",
      "Unique words before ignoring: 109\n",
      "Ignoring words with occurence < 1\n",
      "Unique words after ignoring: 109\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "print(x.shape)\r\n",
    "print(y.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(474, 100, 109)\n",
      "(474, 109)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model creation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are four different types of layers:\n",
    "\n",
    "LSTM layers is a Recurrent Neural Net layer that takes a sequence as an input and can return either sequences (return_sequences=True) or a matrix.\n",
    "\n",
    "Dropout layers are a regularisation technique that consists of setting a fraction of input units to 0 at each update during the training to prevent overfitting. The fraction is determined by the parameter used with the layer.\n",
    "\n",
    "Dense layers or fully connected layers is a fully connected neural network layer where each input node is connected to each output node.\n",
    "\n",
    "The Activation layer determines what activation function our neural network will use to calculate the output of a node."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "source": [
    "# upgraded lstm model\r\n",
    "def create_network(num_units, num_dense, input_shape):\r\n",
    "    \"\"\"\r\n",
    "    Builds and compiles a simple RNN model\r\n",
    "    Param:\r\n",
    "              num_units: Number of units of a the simple RNN layer\r\n",
    "              num_dense: Number of neurons in the dense layer followed by the RNN layer\r\n",
    "              input_shape: input_shape\r\n",
    "    \"\"\"\r\n",
    "    model = Sequential()\r\n",
    "    model.add(Bidirectional(LSTM(num_units, input_shape=input_shape, return_sequences=True)))\r\n",
    "    model.add(Dense(num_dense))\r\n",
    "    model.add(Dropout(0.3))\r\n",
    "    model.add(LSTM(num_units, return_sequences=True))\r\n",
    "    model.add(Dense(num_dense))\r\n",
    "    model.add(Dropout(0.3))\r\n",
    "    model.add(LSTM(num_units))\r\n",
    "    model.add(Dense(num_dense))\r\n",
    "    model.add(Dropout(0.3))\r\n",
    "    model.add(Activation(\"softmax\"))\r\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")\r\n",
    "\r\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "source": [
    "model = create_network(num_units=x.shape[0], num_dense=x.shape[2], input_shape=(x.shape[1],x.shape[2]))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "source": [
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_26 (LSTM)               (None, 100, 474)          1107264   \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 100, 109)          51775     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 100, 109)          0         \n",
      "_________________________________________________________________\n",
      "lstm_27 (LSTM)               (None, 100, 474)          1107264   \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 100, 109)          51775     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 100, 109)          0         \n",
      "_________________________________________________________________\n",
      "lstm_28 (LSTM)               (None, 474)               1107264   \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 109)               51775     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 109)               0         \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 109)               0         \n",
      "=================================================================\n",
      "Total params: 3,477,117\n",
      "Trainable params: 3,477,117\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "source": [
    "model.fit(x, y, epochs=20)#, batch_size=128)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "15/15 [==============================] - 25s 1s/step - loss: 5.1869\n",
      "Epoch 2/20\n",
      "15/15 [==============================] - 18s 1s/step - loss: 4.2229\n",
      "Epoch 3/20\n",
      "15/15 [==============================] - 17s 1s/step - loss: 4.0632\n",
      "Epoch 4/20\n",
      "15/15 [==============================] - 17s 1s/step - loss: 4.0789\n",
      "Epoch 5/20\n",
      "15/15 [==============================] - 17s 1s/step - loss: 4.1008\n",
      "Epoch 6/20\n",
      "15/15 [==============================] - 17s 1s/step - loss: 4.1042\n",
      "Epoch 7/20\n",
      "15/15 [==============================] - 17s 1s/step - loss: 4.0860\n",
      "Epoch 8/20\n",
      "15/15 [==============================] - 18s 1s/step - loss: 4.0748\n",
      "Epoch 9/20\n",
      "15/15 [==============================] - 18s 1s/step - loss: 4.0216\n",
      "Epoch 10/20\n",
      "15/15 [==============================] - 17s 1s/step - loss: 4.0077\n",
      "Epoch 11/20\n",
      "15/15 [==============================] - 17s 1s/step - loss: 3.8819\n",
      "Epoch 12/20\n",
      "15/15 [==============================] - 17s 1s/step - loss: 3.8662\n",
      "Epoch 13/20\n",
      "15/15 [==============================] - 17s 1s/step - loss: 3.8503\n",
      "Epoch 14/20\n",
      "15/15 [==============================] - 17s 1s/step - loss: 3.6249\n",
      "Epoch 15/20\n",
      "15/15 [==============================] - 18s 1s/step - loss: 3.8249\n",
      "Epoch 16/20\n",
      "15/15 [==============================] - 18s 1s/step - loss: 3.6637\n",
      "Epoch 17/20\n",
      "15/15 [==============================] - 18s 1s/step - loss: 3.6434\n",
      "Epoch 18/20\n",
      "15/15 [==============================] - 18s 1s/step - loss: 3.6074\n",
      "Epoch 19/20\n",
      "15/15 [==============================] - 18s 1s/step - loss: 3.5221\n",
      "Epoch 20/20\n",
      "15/15 [==============================] - 17s 1s/step - loss: 3.4055\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2333af7d088>"
      ]
     },
     "metadata": {},
     "execution_count": 141
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "source": [
    "# save the model\r\n",
    "model.save(path_3 + \"model_2_lstm.h5\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "source": [
    "# load the model \r\n",
    "# Baseline LSTM model - model_1_lstm\r\n",
    "# Updated LSTM model - model_2_lstm\r\n",
    "\r\n",
    "model_2_lstm = tf.keras.models.load_model(path_3 + \"model_2_lstm.h5\")\r\n",
    "model_2_lstm.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_26 (LSTM)               (None, 100, 474)          1107264   \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 100, 109)          51775     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 100, 109)          0         \n",
      "_________________________________________________________________\n",
      "lstm_27 (LSTM)               (None, 100, 474)          1107264   \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 100, 109)          51775     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 100, 109)          0         \n",
      "_________________________________________________________________\n",
      "lstm_28 (LSTM)               (None, 474)               1107264   \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 109)               51775     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 109)               0         \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 109)               0         \n",
      "=================================================================\n",
      "Total params: 3,477,117\n",
      "Trainable params: 3,477,117\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "source": [
    "def sample(preds, temperature=1.0):\r\n",
    "    # helper function to sample an index from a probability array\r\n",
    "    preds = np.asarray(preds).astype(\"float64\")\r\n",
    "    preds = np.log(preds) / temperature\r\n",
    "    exp_preds = np.exp(preds)\r\n",
    "    preds = exp_preds / np.sum(exp_preds)\r\n",
    "    probas = np.random.multinomial(1, preds, 1)\r\n",
    "    return np.argmax(probas)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "source": [
    "def generate_notes(notes, model, temperature=1.0):\r\n",
    "    \"\"\" \r\n",
    "    Generate notes from the neural network based on a sequence of notes \r\n",
    "    \"\"\"\r\n",
    "    # pick a random sequence from the input as a starting point for the prediction\r\n",
    "    start = np.random.randint(0, len(notes)-100-1)\r\n",
    "\r\n",
    "    pitchnames = sorted(set(notes))\r\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames)) \r\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\r\n",
    "    \r\n",
    "    pattern = notes[start: (start+100)] \r\n",
    "    prediction_output = []\r\n",
    "    patterns = []\r\n",
    "\r\n",
    "    # generate 500 notes, roughly two minutes of music\r\n",
    "    for note_index in range(100):\r\n",
    "        prediction_input = np.zeros((1, 100, len(pitchnames)))\r\n",
    "        for j, note in enumerate(pattern):\r\n",
    "            prediction_input[0, j, note_to_int[note]] = 1.0\r\n",
    "        preds = model.predict(prediction_input, verbose=0)[0] \r\n",
    "        next_index = sample(preds, temperature=temperature)\r\n",
    "        next_note = int_to_note[next_index]\r\n",
    "\r\n",
    "        pattern = pattern[1:]\r\n",
    "        pattern.append(next_note)\r\n",
    "\r\n",
    "        prediction_output.append(next_note)\r\n",
    "\r\n",
    "        patterns.append(next_index)\r\n",
    "        #patterns = patterns[1:len(patterns)]\r\n",
    "\r\n",
    "    return prediction_output, patterns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "source": [
    "prediction_output, patterns = generate_notes(notes=load_chopin, model=model_2_lstm, temperature=1.0)\r\n",
    "print(prediction_output)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['E6', 'B5', 'F5', 'E2', 'NULL', '4.8', '1.6', '9', 'NULL', 'NULL', '4.7.11', '5.10', 'NULL', 'NULL', 'E4', 'E2', 'D6', 'F2', 'A5', 'C2', '9.0.4', 'B2', '0.4', 'G4', '9.0.4', '2.5', 'E2', 'C2', '2.8', 'B1', 'E-6', '9.0.3', 'A2', '2.4', 'C#6', 'NULL', '8.11.2.4', 'NULL', '0.4', '6.9.0', 'NULL', '11.4', 'C#6', '2.5', 'NULL', '0.4', '0.4', '2.4', '5.11', '6.9.0', '0.4', '5.10', 'C4', 'NULL', 'NULL', 'D2', 'C6', 'C#4', '5.7', '9.2', '5.10', 'C2', '1.5', '3.9', '11.4', 'NULL', '2.5', 'C2', '2.5', 'A2', 'B2', 'NULL', 'NULL', 'B4', 'D2', 'NULL', '5.11', '6.9.11', '0.3.6', 'NULL', 'E2', '5.7', 'A2', 'D4', '9.0.4', '5.7', '10.2', 'NULL', '9.1', 'E3', 'D4', 'E2', '2.8', '10.2', 'C4', '0.4', 'B1', 'E2', 'A1', 'G4']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Output"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "source": [
    "def create_midi(prediction_output, patterns, path):\r\n",
    "    \"\"\" convert the output from the prediction to notes and create a midi file from the notes\"\"\"\r\n",
    "    \r\n",
    "    offset = 0\r\n",
    "    output_notes = []\r\n",
    "\r\n",
    "    # create note and chord objects based on the values generated by the model\r\n",
    "    for pattern in prediction_output:\r\n",
    "        # pattern is a chord\r\n",
    "        if ('.' in pattern) or pattern.isdigit():\r\n",
    "            notes_in_chord = pattern.split('.')\r\n",
    "            notes = []\r\n",
    "            for current_note in notes_in_chord:\r\n",
    "                new_note = note.Note(int(current_note))\r\n",
    "                new_note.storedInstrument = instrument.Piano()\r\n",
    "                notes.append(new_note)\r\n",
    "            new_chord = chord.Chord(notes)\r\n",
    "            new_chord.offset = offset\r\n",
    "            output_notes.append(new_chord)\r\n",
    "        # pattern is a rest\r\n",
    "        elif (\"NULL\" in pattern):\r\n",
    "            new_rest = note.Rest(pattern)\r\n",
    "            output_notes.append(new_rest)\r\n",
    "        # pattern is a note\r\n",
    "        else:\r\n",
    "            new_note = note.Note(pattern)   \r\n",
    "            new_note.offset = offset\r\n",
    "            new_note.storedInstrument = instrument.Piano()\r\n",
    "            output_notes.append(new_note)\r\n",
    "\r\n",
    "        # increase offset each iteration so that notes do not stack\r\n",
    "        offset += 0.5\r\n",
    "\r\n",
    "    midi_stream = stream.Stream(output_notes)\r\n",
    "\r\n",
    "    midi_stream.write(\"midi\", fp= path + \"test_output_1_lstm1.mid\")   # first output 01/07/2021\r\n",
    "\r\n",
    "    return midi_stream"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "source": [
    "create_midi = create_midi(prediction_output, patterns, path_4)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "source": [
    "def play_music(music_file):\r\n",
    "    \"\"\"\r\n",
    "    Play music given a midi file path\r\n",
    "    \"\"\"\r\n",
    "    import music21\r\n",
    "    try:\r\n",
    "        # allow to stop the piece \r\n",
    "        pygame.mixer.init()\r\n",
    "        clock = pygame.time.Clock() \r\n",
    "        pygame.mixer.music.load(music_file)\r\n",
    "        pygame.mixer.music.play()\r\n",
    "        while pygame.mixer.music.get_busy():\r\n",
    "            # check if playback has finished\r\n",
    "            clock.tick(10)\r\n",
    "\r\n",
    "        freq = 44100    # audio CD quality\r\n",
    "        bitsize = -16   # unsigned 16 bit\r\n",
    "        channels = 2    # 1 is mono, 2 is stereo\r\n",
    "        buffer = 1024    # number of samples\r\n",
    "        pygame.mixer.init(freq, bitsize, channels, buffer)\r\n",
    "\r\n",
    "    except KeyboardInterrupt:\r\n",
    "        while True:\r\n",
    "            action = input('Enter Q to Quit, Enter to Skip.').lower()\r\n",
    "            if action == 'q':\r\n",
    "                pygame.mixer.music.fadeout(1000)\r\n",
    "                pygame.mixer.music.stop()\r\n",
    "            else:\r\n",
    "                break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "source": [
    "# Plays music when the cell is executed \r\n",
    "\r\n",
    "play_music(path_4 + \"test_output_1_lstm1.mid\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "import gc\r\n",
    "gc.collect()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "16353"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d8a740277f67c33143a8e5c8e55f738530a350d8def4a85d8635b690074994c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}